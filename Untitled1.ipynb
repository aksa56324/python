{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0353adbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0802eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 19.0 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ------------------------------------- 298.0/298.0 KB 18.0 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 KB 5.4 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB 4.5 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp39-cp39-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.8/267.8 KB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\desktop\\nlps\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.2.0 nltk-3.7 regex-2022.10.31 tqdm-4.64.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\LENOVO\\Desktop\\nlps\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74c071e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9bcb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a4bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00e3b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is kousthubh.', 'My name is dxddd.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"My name is kousthubh. My name is dxddd.\"\n",
    "sent_tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecca5d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['briyani', 'is', 'good', 'and', 'very', 'delicious']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1=\"briyani is good and very delicious\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06dad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\LENOVO\\Desktop\\BBC News Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4cb892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qpr keeper day heads for preston queens park rangers keeper chris day is set to join preston on a month s loan.',\n",
       " 'day has been displaced by the arrival of simon royce  who is in his second month on loan from charlton.',\n",
       " 'qpr have also signed italian generoso rossi.',\n",
       " 'r s manager ian holloway said:  some might say it s a risk as he can t be recalled during that month and simon royce can now be recalled by charlton.',\n",
       " 'but i have other irons in the fire.',\n",
       " 'i have had a  yes  from a couple of others should i need them.',\n",
       " 'day s rangers contract expires in the summer.',\n",
       " 'meanwhile  holloway is hoping to complete the signing of middlesbrough defender andy davies - either permanently or again on loan - before saturday s match at ipswich.',\n",
       " 'davies impressed during a recent loan spell at loftus road.',\n",
       " 'holloway is also chasing bristol city midfielder tom doherty.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(data[\"Text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaaea3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qpr',\n",
       " 'keeper',\n",
       " 'day',\n",
       " 'heads',\n",
       " 'for',\n",
       " 'preston',\n",
       " 'queens',\n",
       " 'park',\n",
       " 'rangers',\n",
       " 'keeper',\n",
       " 'chris',\n",
       " 'day',\n",
       " 'is',\n",
       " 'set',\n",
       " 'to',\n",
       " 'join',\n",
       " 'preston',\n",
       " 'on',\n",
       " 'a',\n",
       " 'month',\n",
       " 's',\n",
       " 'loan',\n",
       " '.',\n",
       " 'day',\n",
       " 'has',\n",
       " 'been',\n",
       " 'displaced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'arrival',\n",
       " 'of',\n",
       " 'simon',\n",
       " 'royce',\n",
       " 'who',\n",
       " 'is',\n",
       " 'in',\n",
       " 'his',\n",
       " 'second',\n",
       " 'month',\n",
       " 'on',\n",
       " 'loan',\n",
       " 'from',\n",
       " 'charlton',\n",
       " '.',\n",
       " 'qpr',\n",
       " 'have',\n",
       " 'also',\n",
       " 'signed',\n",
       " 'italian',\n",
       " 'generoso',\n",
       " 'rossi',\n",
       " '.',\n",
       " 'r',\n",
       " 's',\n",
       " 'manager',\n",
       " 'ian',\n",
       " 'holloway',\n",
       " 'said',\n",
       " ':',\n",
       " 'some',\n",
       " 'might',\n",
       " 'say',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'as',\n",
       " 'he',\n",
       " 'can',\n",
       " 't',\n",
       " 'be',\n",
       " 'recalled',\n",
       " 'during',\n",
       " 'that',\n",
       " 'month',\n",
       " 'and',\n",
       " 'simon',\n",
       " 'royce',\n",
       " 'can',\n",
       " 'now',\n",
       " 'be',\n",
       " 'recalled',\n",
       " 'by',\n",
       " 'charlton',\n",
       " '.',\n",
       " 'but',\n",
       " 'i',\n",
       " 'have',\n",
       " 'other',\n",
       " 'irons',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fire',\n",
       " '.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'had',\n",
       " 'a',\n",
       " 'yes',\n",
       " 'from',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'others',\n",
       " 'should',\n",
       " 'i',\n",
       " 'need',\n",
       " 'them',\n",
       " '.',\n",
       " 'day',\n",
       " 's',\n",
       " 'rangers',\n",
       " 'contract',\n",
       " 'expires',\n",
       " 'in',\n",
       " 'the',\n",
       " 'summer',\n",
       " '.',\n",
       " 'meanwhile',\n",
       " 'holloway',\n",
       " 'is',\n",
       " 'hoping',\n",
       " 'to',\n",
       " 'complete',\n",
       " 'the',\n",
       " 'signing',\n",
       " 'of',\n",
       " 'middlesbrough',\n",
       " 'defender',\n",
       " 'andy',\n",
       " 'davies',\n",
       " '-',\n",
       " 'either',\n",
       " 'permanently',\n",
       " 'or',\n",
       " 'again',\n",
       " 'on',\n",
       " 'loan',\n",
       " '-',\n",
       " 'before',\n",
       " 'saturday',\n",
       " 's',\n",
       " 'match',\n",
       " 'at',\n",
       " 'ipswich',\n",
       " '.',\n",
       " 'davies',\n",
       " 'impressed',\n",
       " 'during',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'loan',\n",
       " 'spell',\n",
       " 'at',\n",
       " 'loftus',\n",
       " 'road',\n",
       " '.',\n",
       " 'holloway',\n",
       " 'is',\n",
       " 'also',\n",
       " 'chasing',\n",
       " 'bristol',\n",
       " 'city',\n",
       " 'midfielder',\n",
       " 'tom',\n",
       " 'doherty',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(data[\"Text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28189a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2ec8afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "320ad1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cde60a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "ls=LancasterStemmer()\n",
    "ss=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89695905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank\n",
      "thank\n",
      "thank\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem(\"thankfully\"))\n",
    "print(ls.stem(\"thankfully\"))\n",
    "print(ss.stem(\"thankfully\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9dc684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chang\n",
      "chang\n",
      "chang\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem(\"changing\"))\n",
    "print(ls.stem(\"changing\"))\n",
    "print(ss.stem(\"changing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d886baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow=word_tokenize(data[\"Text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49ce8b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qpr</td>\n",
       "      <td>qpr</td>\n",
       "      <td>qpr</td>\n",
       "      <td>qpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keeper</td>\n",
       "      <td>keeper</td>\n",
       "      <td>keep</td>\n",
       "      <td>keeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heads</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queens</td>\n",
       "      <td>queen</td>\n",
       "      <td>queen</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>park</td>\n",
       "      <td>park</td>\n",
       "      <td>park</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rangers</td>\n",
       "      <td>ranger</td>\n",
       "      <td>rang</td>\n",
       "      <td>ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>keeper</td>\n",
       "      <td>keeper</td>\n",
       "      <td>keep</td>\n",
       "      <td>keeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chris</td>\n",
       "      <td>chri</td>\n",
       "      <td>chris</td>\n",
       "      <td>chris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>join</td>\n",
       "      <td>join</td>\n",
       "      <td>join</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>month</td>\n",
       "      <td>month</td>\n",
       "      <td>mon</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3\n",
       "0       qpr      qpr      qpr      qpr\n",
       "1    keeper   keeper     keep   keeper\n",
       "2       day      day      day      day\n",
       "3     heads     head     head     head\n",
       "4       for      for      for      for\n",
       "5   preston  preston  preston  preston\n",
       "6    queens    queen    queen    queen\n",
       "7      park     park     park     park\n",
       "8   rangers   ranger     rang   ranger\n",
       "9    keeper   keeper     keep   keeper\n",
       "10    chris     chri    chris    chris\n",
       "11      day      day      day      day\n",
       "12       is       is       is       is\n",
       "13      set      set      set      set\n",
       "14       to       to       to       to\n",
       "15     join     join     join     join\n",
       "16  preston  preston  preston  preston\n",
       "17       on       on       on       on\n",
       "18        a        a        a        a\n",
       "19    month    month      mon    month"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps1=[]\n",
    "ls1=[]\n",
    "ss1=[]\n",
    "for y in word_tokenize(data[\"Text\"][0]):\n",
    "    ps1.append(ps.stem(y))\n",
    "    ls1.append(ls.stem(y))\n",
    "    ss1.append(ss.stem(y))\n",
    "pd.DataFrame([ow,ps1,ls1,ss1]).T.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4249145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "003a5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2f6a6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(\"walking\",pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c808bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de6d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
